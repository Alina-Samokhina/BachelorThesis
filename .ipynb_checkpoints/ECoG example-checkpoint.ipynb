{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import os.path\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, sosfilt\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, sosfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ecog_and_motions(dir):\n",
    "    n_ch = len(glob.glob(os.path.join(dir, 'ECoG_ch*.mat')))\n",
    "    ECoG = []\n",
    "    for ch in range(1, n_ch + 1):\n",
    "        ECoGData = loadmat(os.path.join(dir, 'ECoG_ch%d.mat' % ch))\n",
    "        ECoGData = ECoGData['ECoGData_ch%d' % ch]\n",
    "        ECoG.append(ECoGData[0])\n",
    "\n",
    "    ECoG = np.array(ECoG)\n",
    "\n",
    "    Motion = loadmat(os.path.join(dir, 'Motion.mat'))\n",
    "    MotionTime = Motion['MotionTime']\n",
    "    Motion = Motion['MotionData']\n",
    "        \n",
    "    LSHO = Motion[0,:]\n",
    "    LELB = Motion[1,:]\n",
    "    LWRI = Motion[2,:]\n",
    "    RSHO = Motion[3,:]\n",
    "    RELB = Motion[4,:]\n",
    "    RWRI = Motion[5,:]\n",
    "    \n",
    "    Time = loadmat(os.path.join(dir, 'ECoG_time.mat'))\n",
    "    Time = Time['ECoGTime']\n",
    "\n",
    "    return ECoG.T, LSHO[0], LELB[0], LWRI[0], RSHO[0], RELB[0], RWRI[0], Time.T, MotionTime.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_needed_data(ECoG, LSHO, LELB, LWRI, RSHO, RELB, RWRI, Time, MotionTime):\n",
    "    \n",
    "    body_center = (LSHO - RSHO)/2 #It is a static point in this experiment\n",
    "    motion_left_hand = LWRI - body_center #centering motion\n",
    "    \n",
    "    return ECoG, motion_left_hand"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def read_ECoG_from_csv(signal_file_path, motion_file_path):\n",
    "    signal_df = pd.read_csv(signal_file_path)\n",
    "    motion_df = pd.read_csv(motion_file_path)\n",
    "    left_shoulder = motion_df.loc[0,motion_df.columns.str.contains('LSH')].values\n",
    "    right_shoulder = motion_df.loc[0,motion_df.columns.str.contains('RSH')].values\n",
    "    body_center = (left_shoulder - right_shoulder)/2 #It is a static point in this experiment\n",
    "    motion_left_hand = motion_df[motion_df.columns[motion_df.columns.str.contains('Motion')].\n",
    "                                 append((motion_df.columns[motion_df.columns.str.contains('LWR')]))].values\n",
    "    motion_left_hand[:,1:] -= body_center #centering motion\n",
    "    return signal_df.values, motion_left_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'Data\\\\20100802S1_ECoG_Motion6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECoG, LSHO, LELB, LWRI, RSHO, RELB, RWRI, time, motion_time =  get_ecog_and_motions(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = extract_needed_data(ECoG, LSHO, LELB, LWRI, RSHO, RELB, RWRI, time, motion_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_data = np.c_[time, x]\n",
    "motion_data = np.c_[motion_time, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synchronize_interpol(signal_data, motion_data): \n",
    "    start = max(signal_data[1, 0],motion_data[1,0])\n",
    "    end = min(signal_data[-1, 0],motion_data[-1,0])\n",
    "\n",
    "    #cutting signal and motion, only overlapping time left\n",
    "    signal_data = signal_data[:,:][(signal_data[:,0]>=start)]\n",
    "    signal_data = signal_data[:,:][(signal_data[:,0]<=end)]\n",
    "    motion_data = motion_data[:,:][motion_data[:,0]>= start] \n",
    "    motion_data = motion_data[:,:][motion_data[:,0]<= end]\n",
    "    M = []\n",
    "    #signal and motion have different time stamps, we need to synchronise them\n",
    "    #interpolating motion and calculating arm position in moments of \"signal time\"\n",
    "    for i in range(1,motion_data.shape[1]):\n",
    "        interpol = interp1d(motion_data[:,0],motion_data[:,i],kind=\"cubic\")\n",
    "        x = interpol(signal_data[:,0])\n",
    "        M.append(x)\n",
    "\n",
    "    #downsampling in 10 times to get faster calcultions\n",
    "\n",
    "    ecog_signal = signal_data[::10,1:]\n",
    "    motion = np.array(M).T[::10,:]\n",
    "    time = signal_data[::10,0]\n",
    "    \n",
    "    \n",
    "    #self.signal = signal_data[:,1:]\n",
    "    #self.motion = np.array(M).T[:,:]\n",
    "    #self.time = signal_data[:,0]\n",
    "\n",
    "    return ecog_signal, motion, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal filtering (not sure that it works correctly)\n",
    "def bandpass_filter(ecog_signal, lowcut, highcut, fs = 100, order=7):\n",
    "    nyq =  fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    sos = signal.butter(order,  (low, high), btype='band',analog=False,output='sos')\n",
    "    filtered_signal = np.array([sosfilt(sos, ecog_signal[:,i]) for i in range(ecog_signal.shape[1])])\n",
    "\n",
    "    return filtered_signal.T\n",
    "\n",
    "    #Generating a scalogram by wavelet transformation \n",
    "def scalo(ecog_signal, motion, time, window, freqs,start,end, step = 100): #window in sec,freqs in Hz, step in ms\n",
    "    #div = 1\n",
    "    X = ecog_signal[start:end,:]\n",
    "    div = 10 #downsampling\n",
    "    window_len = int(((window * 1000 // step) + 2) * step//div)\n",
    "    scalo = np.empty((X.shape[0]-window_len,X.shape[1],freqs.shape[0],(window * 1000 // step) + 2))\n",
    "    for i in range(X.shape[1]):\n",
    "        for j in range(window_len,X.shape[0]):\n",
    "            scalo[j-window_len,i,:,:] = signal.cwt(data = X[j-window_len:j,i],\n",
    "                                                    wavelet=signal.morlet,widths = freqs)[:,::step//div] **2\n",
    "    return scalo, motion[start+window_len:end,:], time[start+window_len:end]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecog_signal, motion, time = synchronize_interpol(signal_data, motion_data)\n",
    "filtered_signal = bandpass_filter(ecog_signal, lowcut=0.2,highcut=60,fs = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\scipy\\signal\\wavelets.py:364: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  mode='same')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 54min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#works for a long time, needs about 1 hour to preprocess 15 min experiment\n",
    "freq = np.array([i for i in range(10,150,15)]) \n",
    "scalo,motion,time = scalo(ecog_signal, motion, time, 1,freq,start = 0,end = 104000) # preprocess first 3000(30 sec) objects of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scalo.reshape((scalo.shape[0],scalo.shape[1]*scalo.shape[2]*scalo.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PLSRegression(n_components = 80)\n",
    "model.fit(X[0:10000],motion[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,6))\n",
    "plt.plot(time[0:10000],Y_pred[:,0], color = 'orange')\n",
    "plt.plot(time[0:10000],motion[0:10000,0], color = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(motion[:10000], Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
